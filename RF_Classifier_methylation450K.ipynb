{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0OlckPF7DB25wEgtwNgG2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadunchanna98/MultiOmics-CervicalCancer-MachineLearning-DataProcessing/blob/main/RF_Classifier_methylation450K.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "zA0ZMstdcegf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkmZg4Tic6MC",
        "outputId": "3c021b03-8938-4b61-ee41-4d574d2bb212"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/RESEACH/TCGA Cervical Cancer (CESC)/methilation450K-Preprocessed-data/features_200_samples_96_methilation450K.csv')"
      ],
      "metadata": {
        "id": "R7Hb1qYndBUL"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rondom forest for 96 samples"
      ],
      "metadata": {
        "id": "B_Ky49Z1fvot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saBxU-EwdTIh",
        "outputId": "0eb163a1-62c7-4e33-e55c-d084d7055081"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96, 203)"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop(\"Unnamed: 0\",axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "bLNPxf5sgAKy"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If4IUyPfgEek",
        "outputId": "3339faa0-27d1-4505-876a-1d9019b88e0a"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96, 202)"
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df1['histological_type'] = label_encoder.fit_transform(df1['histological_type'])"
      ],
      "metadata": {
        "id": "VBF3M7Ask17S"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### take 50 featues and 96 samples"
      ],
      "metadata": {
        "id": "GF8eORdLidEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df1.iloc[:, 2:52]  # Select columns from index 2 to 21 (exclusive)\n",
        "y = df1['histological_type']"
      ],
      "metadata": {
        "id": "Y3vF_0Grg7z1"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize KFold with 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "1BWw4OlbijPM"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists to store evaluation metrics for each fold\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []"
      ],
      "metadata": {
        "id": "U343TQvuj2-G"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the random forest model\n",
        "classifier = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "96bSgDqikKj4"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the model's performance for this fold\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))\n",
        "    f1_scores.append(f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "g7zO8xp3j5wZ"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean and standard deviation of evaluation metrics\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "# Print the mean and standard deviation of evaluation metrics\n",
        "print(f'Mean Accuracy: {mean_accuracy:.4f} (±{std_accuracy:.4f})')\n",
        "print(f'Mean Precision: {mean_precision:.4f} (±{std_precision:.4f})')\n",
        "print(f'Mean Recall: {mean_recall:.4f} (±{std_recall:.4f})')\n",
        "print(f'Mean F1-score: {mean_f1:.4f} (±{std_f1:.4f})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPYeOoiKka7m",
        "outputId": "8643630d-e481-47f5-9bf9-9133f2478812"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy: 0.9256 (±0.0490)\n",
            "Mean Precision: 0.9375 (±0.1008)\n",
            "Mean Recall: 0.9214 (±0.1086)\n",
            "Mean F1-score: 0.9203 (±0.0647)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### take 200 featues and 96 samples\n"
      ],
      "metadata": {
        "id": "5hXUeqe1mx7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df1.iloc[:, 2:202]\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the model's performance for this fold\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))\n",
        "    f1_scores.append(f1_score(y_test, y_pred))\n",
        "\n",
        "# Calculate mean and standard deviation of evaluation metrics\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "# Print the mean and standard deviation of evaluation metrics\n",
        "print(f'Mean Accuracy: {mean_accuracy:.4f} (±{std_accuracy:.4f})')\n",
        "print(f'Mean Precision: {mean_precision:.4f} (±{std_precision:.4f})')\n",
        "print(f'Mean Recall: {mean_recall:.4f} (±{std_recall:.4f})')\n",
        "print(f'Mean F1-score: {mean_f1:.4f} (±{std_f1:.4f})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ2HvlaHlMsz",
        "outputId": "0bc02678-e5ce-44c0-cc75-35d6f5487287"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy: 0.8844 (±0.0854)\n",
            "Mean Precision: 0.8725 (±0.1804)\n",
            "Mean Recall: 0.9214 (±0.1086)\n",
            "Mean F1-score: 0.8762 (±0.1027)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df1.iloc[:, 2:22]\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the model's performance for this fold\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))\n",
        "    f1_scores.append(f1_score(y_test, y_pred))\n",
        "\n",
        "# Calculate mean and standard deviation of evaluation metrics\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "# Print the mean and standard deviation of evaluation metrics\n",
        "print(f'Mean Accuracy: {mean_accuracy:.4f} (±{std_accuracy:.4f})')\n",
        "print(f'Mean Precision: {mean_precision:.4f} (±{std_precision:.4f})')\n",
        "print(f'Mean Recall: {mean_recall:.4f} (±{std_recall:.4f})')\n",
        "print(f'Mean F1-score: {mean_f1:.4f} (±{std_f1:.4f})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkyK0XwdsjXy",
        "outputId": "6eecdc9b-77bb-4eae-a1b6-6013e4fa35cf"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy: 0.8644 (±0.0653)\n",
            "Mean Precision: 0.8425 (±0.1761)\n",
            "Mean Recall: 0.8964 (±0.1162)\n",
            "Mean F1-score: 0.8489 (±0.0928)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df1.iloc[:, 2:82]\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the model's performance for this fold\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))\n",
        "    f1_scores.append(f1_score(y_test, y_pred))\n",
        "\n",
        "# Calculate mean and standard deviation of evaluation metrics\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "# Print the mean and standard deviation of evaluation metrics\n",
        "print(f'Mean Accuracy: {mean_accuracy:.4f} (±{std_accuracy:.4f})')\n",
        "print(f'Mean Precision: {mean_precision:.4f} (±{std_precision:.4f})')\n",
        "print(f'Mean Recall: {mean_recall:.4f} (±{std_recall:.4f})')\n",
        "print(f'Mean F1-score: {mean_f1:.4f} (±{std_f1:.4f})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds8TPKFis0l6",
        "outputId": "23c90934-89aa-4aef-f7e1-8bb46c4d5e1d"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy: 0.9156 (±0.0425)\n",
            "Mean Precision: 0.9375 (±0.1008)\n",
            "Mean Recall: 0.8881 (±0.1287)\n",
            "Mean F1-score: 0.9003 (±0.0678)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rondom forest for 150 samples"
      ],
      "metadata": {
        "id": "Xl_WoZDAOUnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv('/content/drive/MyDrive/RESEACH/TCGA Cervical Cancer (CESC)/methilation450K-Preprocessed-data/features_200_samples_150_methilation450K.csv')"
      ],
      "metadata": {
        "id": "RECM-iQ4OWH-"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS6_pbmGOtbV",
        "outputId": "60871fd9-fafb-4d29-d43b-4d83ffd4b029"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 204)"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
        "df2.drop(\"histological_type_encoded\",axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "sF9k5bWUOgIj"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFC9lWCxPGMP",
        "outputId": "bf938761-22b1-4bd8-837a-f98c3d1fcf3b"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 202)"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2['histological_type'] = label_encoder.fit_transform(df2['histological_type'])"
      ],
      "metadata": {
        "id": "P5p5EIlKPL_J"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random forest 150 samples 50 features"
      ],
      "metadata": {
        "id": "o-9qWmQ-To3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df2.iloc[:, 2:52]  # Select columns from index 2 to 21 (exclusive)\n",
        "y = df2['histological_type']\n",
        "\n",
        "# Initialize KFold with 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the model's performance for this fold\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))\n",
        "    f1_scores.append(f1_score(y_test, y_pred))\n",
        "\n",
        "# Calculate mean and standard deviation of evaluation metrics\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "# Print the mean and standard deviation of evaluation metrics\n",
        "print(f'Mean Accuracy: {mean_accuracy:.4f} (±{std_accuracy:.4f})')\n",
        "print(f'Mean Precision: {mean_precision:.4f} (±{std_precision:.4f})')\n",
        "print(f'Mean Recall: {mean_recall:.4f} (±{std_recall:.4f})')\n",
        "print(f'Mean F1-score: {mean_f1:.4f} (±{std_f1:.4f})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIHcwb46PclR",
        "outputId": "cff5c96a-3ad1-460b-9e9a-7bae89191326"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy: 0.9333 (±0.0667)\n",
            "Mean Precision: 0.9382 (±0.0793)\n",
            "Mean Recall: 0.9507 (±0.0611)\n",
            "Mean F1-score: 0.9419 (±0.0533)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random forest 150 samples and 200 features"
      ],
      "metadata": {
        "id": "PQONPlT8UnKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df2.iloc[:, 2:202]  # Select columns from index 2 to 21 (exclusive)\n",
        "y = df2['histological_type']\n",
        "\n",
        "# Initialize KFold with 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the model's performance for this fold\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))\n",
        "    f1_scores.append(f1_score(y_test, y_pred))\n",
        "\n",
        "# Calculate mean and standard deviation of evaluation metrics\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "# Print the mean and standard deviation of evaluation metrics\n",
        "print(f'Mean Accuracy: {mean_accuracy:.4f} (±{std_accuracy:.4f})')\n",
        "print(f'Mean Precision: {mean_precision:.4f} (±{std_precision:.4f})')\n",
        "print(f'Mean Recall: {mean_recall:.4f} (±{std_recall:.4f})')\n",
        "print(f'Mean F1-score: {mean_f1:.4f} (±{std_f1:.4f})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILUKysq0Rs2r",
        "outputId": "b5ad09b7-f9a6-41ed-964e-bdebb4e6ccbb"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy: 0.9000 (±0.0537)\n",
            "Mean Precision: 0.8992 (±0.0939)\n",
            "Mean Recall: 0.9096 (±0.0879)\n",
            "Mean F1-score: 0.8975 (±0.0511)\n"
          ]
        }
      ]
    }
  ]
}